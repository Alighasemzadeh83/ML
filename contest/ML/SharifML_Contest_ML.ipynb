{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 dir=rtl align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "    SharifML Contest - ML\n",
    "</font>\n",
    "</h1>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "   \n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معرفی مجموعه داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    در فایل اولیه‌ی این سوال دو مجموعه‌داده با نام‌های <code>train_dataset</code> و <code>test_dataset</code> قرار دارد که به ترتیب مجموعه‌داده مربوط به آموزش و آزمون هستند. این دو به‌ترتیب شامل ۲۵۹۴۱ و ۱۷۰۰ سطر هستند.\n",
    "    <br>\n",
    "    ستون‌های این فایل به شرح زیر است:\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div dir=rtl align=center style=\"direction: rtl;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "| <b>نام ویژگی</b> | <b>توضیح ویژگی</b> |\n",
    "| :---: | :---: |\n",
    "| <code>Class</code> | ستون هدف که کلاس مربوط به آن گونه است.|\n",
    "| <code>Others</code> | ویژگی‌هایی که می‌توانید از آنها برای آموزش مدل خود استفاده کنید. |\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "خواندن مجموعه‌داده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    if not isinstance(value, str):\n",
    "        return value\n",
    "    \n",
    "    if value.strip == \"\":\n",
    "        return np.nan\n",
    "\n",
    "    match = re.match(r\"([0-9.]+)\", value.strip())\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    \n",
    "    return value\n",
    "\n",
    "def preprocess_data(train, test, dict_columns=[]):\n",
    "    for col in dict_columns:\n",
    "        if col in train.columns:\n",
    "            train[col] = train[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "            dict_train = pd.json_normalize(train[col])\n",
    "            dict_train.columns = [f\"{col}_{key}\" for key in dict_train.columns]\n",
    "            train = pd.concat([train, dict_train], axis=1)\n",
    "            train.drop(columns=[col], inplace=True)\n",
    "\n",
    "        if col in test.columns:\n",
    "            test[col] = test[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "            dict_test = pd.json_normalize(test[col])\n",
    "            dict_test.columns = [f\"{col}_{key}\" for key in dict_test.columns]\n",
    "            test = pd.concat([test, dict_test], axis=1)\n",
    "            test.drop(columns=[col], inplace=True)\n",
    "            \n",
    "    for col in train.columns:\n",
    "        if isinstance(train[col].iloc[0], list):\n",
    "            unique_attributes = set([item for sublist in train[col] for item in sublist])\n",
    "            for attribute in unique_attributes:\n",
    "                train[attribute] = train[col].apply(lambda x: 1 if attribute in x else 0)\n",
    "            train.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    for col in test.columns:\n",
    "        if isinstance(test[col].iloc[0], list):\n",
    "            unique_attributes = set([item for sublist in test[col] for item in sublist])\n",
    "            for attribute in unique_attributes:\n",
    "                test[attribute] = test[col].apply(lambda x: 1 if attribute in x else 0)\n",
    "            test.drop(columns=[col], inplace=True)\n",
    "            \n",
    "    for col in train:\n",
    "        train[col] = train[col].apply(lambda x: np.nan if (x == {} or x == []) else x)\n",
    "    for col in test:\n",
    "        test[col] = test[col].apply(lambda x: np.nan if (x == {} or x == []) else x)\n",
    "        \n",
    "    for col in train:\n",
    "        if train[col].dtype == object:\n",
    "            train[col] = train[col].apply(lambda x: extract_numeric(x) if not isinstance(x, (list, dict)) else np.nan)\n",
    "    for col in test:\n",
    "        if test[col].dtype == object:\n",
    "            test[col] = test[col].apply(lambda x: extract_numeric(x) if not isinstance(x, (list, dict)) else np.nan)\n",
    "\n",
    "    single_value_cols = [\n",
    "        col for col in train.columns\n",
    "        if train[col].apply(lambda x: tuple(x) if isinstance(x, list) else x).nunique() <= 1\n",
    "    ]\n",
    "\n",
    "    single_value_cols = [col for col in single_value_cols if col != \"Class\"]\n",
    "\n",
    "    train.drop(columns=single_value_cols, inplace=True)\n",
    "    test.drop(columns=[col for col in single_value_cols if col in test.columns], inplace=True)\n",
    "\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns + [\"Class\"]]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    for col in train.columns:\n",
    "        mode_value = train[col].mode()\n",
    "        if not mode_value.empty:\n",
    "            mode_value = str(mode_value[0])\n",
    "        else:\n",
    "            mode_value = np.nan\n",
    "\n",
    "        train[col].fillna(mode_value, inplace=True)\n",
    "        if col != \"Class\":\n",
    "            test[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "    train = train.reindex(sorted(train.columns), axis=1)\n",
    "    test = test.reindex(sorted(test.columns), axis=1)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = preprocess_data(train_df, test_df, [\"Distribution\", \"Habits\", \"Mating_Habits\", \"Population\"])\n",
    "\n",
    "\n",
    "def label_encode(X):\n",
    "    label_encoders = {}\n",
    "    for col in X.select_dtypes(include=['object']):\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    return label_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "آموزش مدل\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    حال که داده را پاکسازی کرده‌اید، وقت آن است که مدلی آموزش دهید که بتواند متغیر هدف این مسئله را پیش‌بینی کند.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['Class'])\n",
    "y_train = train_df['Class']\n",
    "\n",
    "label_encoders = label_encode(X_train)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# model = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', max_iter=1000, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# model = AdaBoostClassifier(n_estimators=150, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "X_test = test_df\n",
    "for col in X_test.select_dtypes(include=['object']):\n",
    "    le = label_encoders.get(col, None)\n",
    "    if le:\n",
    "        X_test[col] = X_test[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "معیار ارزیابی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    معیاری که برای ارزیابی عملکرد مدل انتخاب کرده‌ایم، <code>f1_score</code> نام دارد.\n",
    "    <br>\n",
    "    این معیار، سنجه ارزیابی کیفیت مدل شماست. به عبارت بهتر در سامانه داوری هم از همین معیار برای نمره‌دهی استفاده شده است.\n",
    "    <br>\n",
    "    پیشنهاد می‌شود با توجه به این معیار، عملکرد مدل خود را بر روی مجموعه‌ی آموزش یا اعتبارسنجی ارزیابی کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای دریافت نمره از این سوال لازم است تا دقت مدل شما از آستانه‌ی ۰.۴ بیشتر باشد.\n",
    "    در صورتی که دقت مدل شما از ۰.۴ کمتر باشد نمره شما \n",
    "    <b>صفر</b>\n",
    "    خواهد شد و در غیر این صورت با فرمول زیر محاسبه می‌شود:\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# Evaluate your model\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    " پیش‌بینی بر روی داده‌ی تست و خروجی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    پیش‌بینی مدل خود بر روی داده‌های آزمون را در یک دیتافریم (<code>dataframe</code>) به فرمت زیر ذخیره کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    توجه داشته باشید که نام دیتافریم باید <code>submission</code> باشد؛ در غیر این‌صورت، سامانه‌ی داوری قادر به ارزیابی خروجی شما نخواهد بود.\n",
    "    این دیتافریم صرفا شامل یک ستون به نام <code>Class</code> است و ۱۷۰۰ سطر دارد.\n",
    "    <br>\n",
    "    به ازای هر سطر موجود در مجموعه‌داده‌ی آزمون، باید یک کلاس پیش‌بینی‌شده داشته باشید و مقدار <code>Class</code> پیش‌بینی مدل شما برای آن سطر است.\n",
    "    به‌عنوان مثال جدول زیر، ۵ سطر ابتدایی دیتافریم <code>submission</code> را نشان می‌دهد. البته این مقادیر به‌صورت فرضی هستند و در جواب شما، ممکن است متفاوت باشند.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<center>\n",
    "<div align=center \n",
    "style=\"direction: ltr;line-height:200%;font-family:vazir;font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    \n",
    "||<code>Class</code>|\n",
    "|:----:|:-----:|\n",
    "|0|Gastropoda|\n",
    "|1|Amphibia|\n",
    "|2|Amphibia|\n",
    "|3|Aves|\n",
    "|4|Amphibia|\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = model.predict(X_test)\n",
    "submission = pd.DataFrame(submission, columns=[\"Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) در غیر این صورت، در پایان مسابقه نمره شما به صفر تغییر خواهد کرد.\n",
    "    <br>\n",
    "    همچنین اگر از گوگل کولب برای اجرای این فایل نوت‌بوک استفاده می‌کنید، قبل از ارسال فایل <code>result.zip</code>، آخرین نسخه‌ی نوت‌بوک خود را دانلود کرده و داخل فایل ارسالی قرار دهید.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['SharifML_Contest_ML.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'SharifML_Contest_ML.ipynb')):\n",
    "    %notebook -e SharifML_Contest_ML.ipynb\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['SharifML_Contest_ML.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
